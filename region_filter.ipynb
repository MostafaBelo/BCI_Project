{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f132f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space structure:\n",
      "  LH vertices: 4098\n",
      "  RH vertices: 4098\n",
      "  Total: 8196\n",
      "\n",
      "Found 8 language ROI labels\n",
      "  parsopercularis-lh: 74 vertices → indices\n",
      "  parsopercularis-rh: 56 vertices → indices\n",
      "  parstriangularis-lh: 59 vertices → indices\n",
      "  parstriangularis-rh: 65 vertices → indices\n",
      "  precentral-lh: 263 vertices → indices\n",
      "  superiortemporal-lh: 180 vertices → indices\n",
      "  superiortemporal-rh: 168 vertices → indices\n",
      "  supramarginal-lh: 211 vertices → indices\n",
      "\n",
      "Total vertices in language ROIs: 1076\n",
      "Min index: 0, Max index: 8186\n",
      "All indices in valid range [0, 8195]? True\n",
      "✓ All indices are valid!\n",
      "\n",
      "ROI configuration saved to 'language_roi_config.json'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from mne.minimum_norm import read_inverse_operator\n",
    "\n",
    "# Load your forward/inverse operators\n",
    "inv_operator = read_inverse_operator('inverse_operator-inv.fif', verbose=False)\n",
    "info = mne.io.read_info(\"info.fif\", verbose=False)\n",
    "\n",
    "# Get the source space from forward solution\n",
    "fwd = mne.read_forward_solution('forward_solution-fwd.fif', verbose=False)\n",
    "src = fwd['src']  # Source space object\n",
    "\n",
    "print(f\"Source space structure:\")\n",
    "print(f\"  LH vertices: {src[0]['nuse']}\")\n",
    "print(f\"  RH vertices: {src[1]['nuse']}\")\n",
    "print(f\"  Total: {src[0]['nuse'] + src[1]['nuse']}\")\n",
    "\n",
    "# Get fsaverage surface\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from pathlib import Path\n",
    "\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "subjects_dir = Path(fs_dir).parent.as_posix()\n",
    "subject = 'fsaverage'\n",
    "\n",
    "# Load labels\n",
    "labels = mne.read_labels_from_annot(subject, parc='aparc', subjects_dir=subjects_dir, verbose=False)\n",
    "\n",
    "# Define language-relevant ROIs\n",
    "language_roi_names = [\n",
    "    # 'superiorfrontal-lh',\n",
    "    # 'precentral-lh',\n",
    "    # 'postcentral-lh',\n",
    "    # 'inferiorparietal-lh',\n",
    "    # 'supramarginal-lh',\n",
    "    # 'superiortemporal-lh',\n",
    "    # 'middletemporal-lh',\n",
    "    # 'inferiororbitalfrontal-lh',\n",
    "    # 'parsopercularis-lh',\n",
    "    # 'parsorbitalis-lh',\n",
    "    # 'parstriangularis-lh',\n",
    "    # 'rostralanteriorcingulate-lh',\n",
    "    # 'caudalanteriorcingulate-lh',\n",
    "    # 'superiorfrontal-rh',\n",
    "    # 'precentral-rh',\n",
    "    # 'postcentral-rh',\n",
    "    # 'inferiorparietal-rh',\n",
    "    # 'supramarginal-rh',\n",
    "    # 'superiortemporal-rh',\n",
    "    # 'middletemporal-rh',\n",
    "    # 'inferiororbitalfrontal-rh',\n",
    "    # 'parsopercularis-rh',\n",
    "    # 'parsorbitalis-rh',\n",
    "    # 'parstriangularis-rh',\n",
    "\n",
    "    # Left hemisphere - PRIMARY language areas\n",
    "    'parsopercularis-lh',      # Broca's area (BA 44)\n",
    "    'parstriangularis-lh',     # Broca's area (BA 45)\n",
    "    'superiortemporal-lh',     # Wernicke's area\n",
    "    'supramarginal-lh',        # Angular gyrus - phonological processing\n",
    "    'precentral-lh',           # Motor cortex - speech production\n",
    "    \n",
    "    # Right hemisphere - prosody and supplementary\n",
    "    'parsopercularis-rh',\n",
    "    'parstriangularis-rh',\n",
    "    'superiortemporal-rh',\n",
    "]\n",
    "\n",
    "# Filter to language ROIs\n",
    "language_labels = [l for l in labels if any(roi in l.name.lower() for roi in language_roi_names)]\n",
    "\n",
    "print(f\"\\nFound {len(language_labels)} language ROI labels\")\n",
    "\n",
    "# Map label vertices to source space indices\n",
    "# Labels have vertices in full surface space; we need indices in our source space\n",
    "roi_vertices = []\n",
    "\n",
    "for label in language_labels:\n",
    "    # Get the source space for this label (lh or rh)\n",
    "    if 'lh' in label.name:\n",
    "        src_hemi = src[0]\n",
    "    else:\n",
    "        src_hemi = src[1]\n",
    "    \n",
    "    # Get the vertices in the source space\n",
    "    src_vertices = src_hemi['vertno']  # indices into the full surface\n",
    "    \n",
    "    # Find intersection: which label vertices are in our source space?\n",
    "    label_verts_in_src = np.intersect1d(label.vertices, src_vertices)\n",
    "    \n",
    "    # Convert to indices into the source space array\n",
    "    # np.searchsorted finds the position in sorted src_vertices\n",
    "    indices = np.searchsorted(src_vertices, label_verts_in_src)\n",
    "    \n",
    "    # Add offset for RH (if this is RH, offset by LH size)\n",
    "    if 'rh' in label.name:\n",
    "        indices = indices + src[0]['nuse']\n",
    "    \n",
    "    roi_vertices.extend(indices.tolist())\n",
    "    print(f\"  {label.name}: {len(label_verts_in_src)} vertices → indices\")\n",
    "\n",
    "roi_vertices = sorted(set(roi_vertices))\n",
    "\n",
    "print(f\"\\nTotal vertices in language ROIs: {len(roi_vertices)}\")\n",
    "print(f\"Min index: {min(roi_vertices)}, Max index: {max(roi_vertices)}\")\n",
    "print(f\"All indices in valid range [0, 8195]? {max(roi_vertices) < 8196}\")\n",
    "\n",
    "if max(roi_vertices) >= 8196:\n",
    "    print(\"ERROR: Still have invalid indices!\")\n",
    "else:\n",
    "    print(\"✓ All indices are valid!\")\n",
    "\n",
    "# Save ROI information\n",
    "import json\n",
    "with open('language_roi_config.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'roi_vertices': roi_vertices,\n",
    "        'roi_labels': [l.name for l in language_labels],\n",
    "        'n_roi_vertices': len(roi_vertices),\n",
    "        'original_n_sources': 8196,\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nROI configuration saved to 'language_roi_config.json'\")\n",
    "\n",
    "def localize_and_extract_rois(data: np.ndarray, \n",
    "                              stop: int | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Localize sensor data to source space and extract only language ROIs.\n",
    "    \n",
    "    Args:\n",
    "        data: shape (n_channels, n_times) - sensor EEG data\n",
    "        stop: end sample (None = use all data)\n",
    "    \n",
    "    Returns:\n",
    "        roi_data: shape (n_roi_vertices, n_times) - source-localized data for language ROIs only\n",
    "    \"\"\"\n",
    "    from mne.minimum_norm import apply_inverse_raw\n",
    "    \n",
    "    raw = mne.io.RawArray(data, info, verbose=False)\n",
    "    \n",
    "    stc_full = apply_inverse_raw(raw, inv_operator, \n",
    "                                 lambda2=1.0/9.0, \n",
    "                                 method='dSPM',\n",
    "                                 buffer_size=5000,\n",
    "                                 start=0, \n",
    "                                 stop=stop,\n",
    "                                 verbose=False)\n",
    "    \n",
    "    roi_data = stc_full.data[roi_vertices, :]\n",
    "    \n",
    "    return roi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4acdc5",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763749eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data = np.load(\"/mnt/D/University/Fall 2025/BCI/Project/shards/words/old/shard_0.npy\", allow_pickle=True)\n",
    "data = np.load(\"/mnt/D/University/Fall 2025/BCI/Project/shards/words/shard_0.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c57fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5372511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['eeg', 'localized_eeg', 'labels'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b683c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][\"localized_eeg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dd832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3438, 120)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"localized_eeg\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010c3926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3438, 152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"localized_eeg\"][25].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

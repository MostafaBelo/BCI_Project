{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156af74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g4/Documents/BCI_Project/BCI_Project/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "from torcheeg.models import EEGNet\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from EEGDataset import EEGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6036bfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92825288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
    "# clip_model = CLIPModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9871a55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 384), dtype('float32'), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode([\"hello world\", \"open source embeddings\"])\n",
    "embeddings.shape, embeddings.dtype, type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28dc0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0fbea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EEGDataset(\"shards\")\n",
    "train_ds, val_ds, test_ds = ds.split_train_valid_test(train_ratio=0.7, valid_ratio=0.15, shuffle=False)\n",
    "\n",
    "train_dl = train_ds.getLoader(batch_size=25, num_workers=0)\n",
    "val_dl = val_ds.getLoader(batch_size=25, num_workers=0)\n",
    "test_dl = test_ds.getLoader(batch_size=25, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54197c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Presents a good case while failing to provide a reason for us to care beyond the very basic dictums of human decency.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d9beda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 384), dtype('float32'), numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode([ds[0][1]])\n",
    "embeddings.shape, embeddings.dtype, type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9248eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 8196, 10000])\n",
      "['Presents a good case while failing to provide a reason for us to care beyond the very basic dictums of human decency.', 'Beautifully crafted, engaging filmmaking that should attract upscale audiences hungry for quality and a nostalgic, twisty yarn that will keep them guessing.', 'Bread, My Sweet has so many flaws it would be easy for critics to shred it.', 'Slow, silly and unintentionally hilarious.', 'Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.', 'Exudes the fizz of a Busby Berkeley musical and the visceral excitement of a sports extravaganza.', \"The film rehashes several old themes and is capped with pointless extremes -- it's insanely violent and very graphic.\", 'Ryan Gosling is, in a word, brilliant as the conflicted Daniel.', \"If Deuces Wild had been tweaked up a notch it would have become a camp adventure, one of those movies that's so bad it starts to become good.\", \"The film's stagecrafts are intimate and therefore bolder than the otherwise calculated artifice that defines and overwhelms the film's production design.\", 'Frida is certainly no disaster, but neither is it the Kahlo movie Frida fans have been looking for.', 'The film often achieves a mesmerizing poetry.', 'A work of astonishing delicacy and force.', \"The movie's plot is almost entirely witless and inane, carrying every gag two or three times beyond its limit to sustain a laugh.\", 'For the most part, the ingredients are there.', \"But if you've paid a matinee price and bought a big tub of popcorn, there's guilty fun to be had here.\", \"There's not much to Fatale, outside of its stylish surprises... but that's OK.\", \"The acting is stiff, the story lacks all trace of wit, the sets look like they were borrowed from Gilligan's Island -- and the CGI Scooby might well be the worst special-effects creation of the year.\", \"This version moves beyond the original's nostalgia for the communal film experiences of yesteryear to a deeper realization of cinema's inability to stand in for true, lived experience.\", \"There's no palpable chemistry between Lopez and male lead Ralph Fiennes, plus the script by Working Girl scribe Kevin Wade is workmanlike in the extreme.\", 'A first-class, thoroughly involving B movie that effectively combines two surefire, beloved genres -- the prison flick and the fight film.', \"The film is so bad it doesn't improve upon the experience of staring at a blank screen.\", 'Weiss and Speck never make a convincing case for the relevance of these two 20th-century footnotes.', 'Another Best of the Year selection.', \"It's all a rather shapeless good time...\"]\n"
     ]
    }
   ],
   "source": [
    "ds[0][0].shape\n",
    "\n",
    "for batch_data, batch_labels in train_dl:\n",
    "    print(batch_data.shape)\n",
    "    print(batch_labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb981eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.text_encoder_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    def forward(self, texts):\n",
    "        embeddings = self.text_encoder_model.encode(texts, convert_to_tensor=True)\n",
    "        return embeddings\n",
    "\n",
    "class LocalizedEEGEncoder(nn.Module):\n",
    "    def __init__(self, ch_count=8196, embedding_dim=384):\n",
    "        super(LocalizedEEGEncoder, self).__init__()\n",
    "\n",
    "        self.temporal = nn.Conv1d(ch_count, 512, 3, padding=1)\n",
    "        self.temporal2 = nn.Conv1d(512, 256, 3, padding=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((256, 1))\n",
    "        self.fc = nn.Linear(256, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.temporal(x))\n",
    "        x = torch.relu(self.temporal2(x))\n",
    "        x = self.avg_pool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class EEGCLIPModel(nn.Module):\n",
    "    def __init__(self, ch_count=8196, embedding_dim=384):\n",
    "        super(EEGCLIPModel, self).__init__()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.eeg_encoder = LocalizedEEGEncoder(ch_count=ch_count, embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, eeg_data, texts):\n",
    "        eeg_embeddings = self.eeg_encoder(eeg_data)\n",
    "        text_embeddings = self.text_encoder(texts)\n",
    "        return eeg_embeddings, text_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157eea70",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb52d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGCLIPModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827f34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_dataloader: DataLoader, valid_loader: DataLoader, epochs: int = 10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            eeg_data, texts = batch\n",
    "            eeg_data = eeg_data.to(torch.float32).to(device)\n",
    "            texts = list(texts)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            eeg_embeddings, text_embeddings = model(eeg_data, texts)\n",
    "\n",
    "            loss = ((eeg_embeddings - text_embeddings) ** 2).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        total_valid_loss = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for batch in tqdm(valid_loader):\n",
    "                eeg_data, texts = batch\n",
    "                eeg_data = eeg_data.to(torch.float32).to(device)\n",
    "                texts = list(texts)\n",
    "\n",
    "                eeg_embeddings, text_embeddings = model(eeg_data, texts)\n",
    "\n",
    "                loss = ((eeg_embeddings - text_embeddings) ** 2).mean()\n",
    "\n",
    "                total_valid_loss += loss.item()\n",
    "        avg_valid_loss = total_valid_loss / len(valid_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]:- Train Loss: {avg_loss:.6f} | Valid Loss: {avg_valid_loss:.6f}\")\n",
    "        \n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e93c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, test_dataloader: DataLoader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            eeg_data, texts = batch\n",
    "            eeg_data = eeg_data.to(device)\n",
    "            texts = list(texts)\n",
    "\n",
    "            eeg_embeddings, text_embeddings = model(eeg_data, texts)\n",
    "\n",
    "            loss = ((eeg_embeddings - text_embeddings) ** 2).mean()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    print(f\"Test Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [01:24<06:55, 46.21s/it]"
     ]
    }
   ],
   "source": [
    "train(model, train_dl, val_dl, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
